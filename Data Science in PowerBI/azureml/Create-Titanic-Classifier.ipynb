{
  "cells": [
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": [
        "from azureml.core import Workspace, Dataset, Datastore, Experiment, Run\n",
        "import math, random, pickle\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "experiment_name = \"titanic_classifier\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[\n  {\n    \"cloudName\": \"AzureCloud\",\n    \"homeTenantId\": \"67269ab6-9b12-4bb4-9781-cdd9ce5a3102\",\n    \"id\": \"d87d4530-ce4e-4d84-b997-7a78d01e2906\",\n    \"isDefault\": true,\n    \"managedByTenants\": [\n      {\n        \"tenantId\": \"2f4a9838-26b7-47ee-be60-ccc1fdec5953\"\n      }\n    ],\n    \"name\": \"Visual Studio Enterprise\",\n    \"state\": \"Enabled\",\n    \"tenantId\": \"67269ab6-9b12-4bb4-9781-cdd9ce5a3102\",\n    \"user\": {\n      \"name\": \"kyle.m.hale@avanade.com\",\n      \"type\": \"user\"\n    }\n  }\n]\nYou have logged in. Now let us find all the subscriptions to which you have access...\n"
        }
      ],
      "source": [
        "!az login -t \"67269ab6-9b12-4bb4-9781-cdd9ce5a3102\"\n",
        "!az account set --subscription \"Visual Studio Enterprise\""
      ]
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": [
        "from azureml.core.authentication import AzureCliAuthentication\n",
        "\n",
        "try:\n",
        "    ws = Workspace.from_config()\n",
        "except:\n",
        "    cli_auth = AzureCliAuthentication()\n",
        "\n",
        "    ws = Workspace(subscription_id=\"d87d4530-ce4e-4d84-b997-7a78d01e2906\",\n",
        "               resource_group=\"mlops-RG\",\n",
        "               workspace_name=\"mlops-AML-WS\",\n",
        "               auth=cli_auth)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Performing interactive authentication. Please follow the instructions on the terminal.\nNote, we have launched a browser for you to login. For old experience with device code, use \"az login --use-device-code\"\nYou have logged in. Now let us find all the subscriptions to which you have access...\nInteractive authentication successfully completed.\n"
        }
      ]
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": [
        "experiment = Experiment(workspace = ws, name = experiment_name)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "{\n  \"name\": \"workspaceblobstore\",\n  \"container_name\": \"azureml-blobstore-6f7dfc08-44b5-438d-a6bc-9c804e0bdd76\",\n  \"account_name\": \"kylemhaleamlsa\",\n  \"protocol\": \"https\",\n  \"endpoint\": \"core.windows.net\"\n}"
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "datastore = Datastore.get_default(workspace=ws)\n",
        "datastore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "titanic_ds = pd.read_csv(\"./data/titanic3.csv\")\n",
        "#drop unnecessary columns for classifier\n",
        "titanic_ds.drop(['name','ticket','fare','cabin','embarked','boat','body','home.dest'], axis=1, inplace=True)\n",
        "\n",
        "#condense Families to unaccompanied boolean\n",
        "titanic_ds['unaccompanied'] = np.where(titanic_ds.sibsp > 0, 1, np.where(titanic_ds['parch'] > 0, 1, 0))\n",
        "titanic_ds.drop(['sibsp', 'parch'], axis=1, inplace=True)\n",
        "\n",
        "#map gender to numeric values\n",
        "genders = {\"male\": 0, \"female\": 1}\n",
        "titanic_ds['sex'] = titanic_ds['sex'].map(genders)\n",
        "\n",
        "#round age to nearest year, and fill in missing values with average age\n",
        "titanic_ds[\"age\"].fillna(titanic_ds[\"age\"].mean(), inplace=True)\n",
        "titanic_ds['age'] = titanic_ds['age'].astype(int)\n",
        "\n",
        "#re-bin ages into groups\n",
        "titanic_ds['age'] = pd.cut(titanic_ds['age'], [-10, 18, 40, 100], labels=[1,2,3]).astype(int)\n",
        "\n",
        "titanic_ds = titanic_ds.reindex(columns=['pclass','age','sex','unaccompanied','survived'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Uploading an estimated of 1 files\nTarget already exists. Skipping upload for data\\titanic-engineered.csv\nUploaded 0 files\n2020-05-13 18:16:08.899961 | ActivityCompleted: Activity=from_delimited_files, HowEnded=Failure, Duration=0.0 [ms], Info = {'activity_id': '525a8679-faf9-452b-bc7b-953e8e07f6b7', 'activity_name': 'from_delimited_files', 'activity_type': 'PublicApi', 'app_name': 'TabularDataset', 'source': 'azureml.dataset', 'version': '1.1.5.1', 'dataprepVersion': ''}, Exception=ModuleNotFoundError; No module named 'azureml.dataprep'\n"
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'azureml.dataprep'",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-12-53712c5fb694>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdatastore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'./data/uploads'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'data'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTabular\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_delimited_files\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatastore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data/titanic-engineered.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32mC:\\tools\\Anaconda3\\lib\\site-packages\\azureml\\data\\_loggerfactory.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0m_LoggerFactory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrack_activity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogger\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivity_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcustom_dimensions\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mal\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'activity_info'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'error_code'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\tools\\Anaconda3\\lib\\site-packages\\azureml\\data\\dataset_factory.py\u001b[0m in \u001b[0;36mfrom_delimited_files\u001b[1;34m(path, validate, include_path, infer_column_types, set_column_types, separator, header, partition_format)\u001b[0m\n\u001b[0;32m    230\u001b[0m                              'ALL_FILES_HAVE_SAME_HEADERS')\n\u001b[0;32m    231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m         dataflow = dataprep().read_csv(_validate_and_normalize_path(path),\n\u001b[0m\u001b[0;32m    233\u001b[0m                                        \u001b[0mverify_exists\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m                                        \u001b[0minclude_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\tools\\Anaconda3\\lib\\site-packages\\azureml\\data\\_dataprep_helper.py\u001b[0m in \u001b[0;36mdataprep\u001b[1;34m()\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_dataprep_installed\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_dataprep_missing_message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m     \u001b[1;32mimport\u001b[0m \u001b[0mazureml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataprep\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_dprep\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m     \u001b[0mcheck_min_version\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_dprep\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'azureml.dataprep'"
          ]
        }
      ],
      "source": [
        "engineered_data_path = './data/uploads/titanic-engineered.csv'\n",
        "titanic_ds.to_csv(engineered_data_path)\n",
        "\n",
        "datastore.upload(src_dir='./data/uploads', target_path='data')\n",
        "\n",
        "dataset = Dataset.Tabular.from_delimited_files(datastore.path('data/titanic-engineered.csv'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = titanic_ds.iloc[ : , :-1].values\n",
        "y = titanic_ds.iloc[ : , 4].values\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.33, random_state=39)\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "run = experiment.start_logging(snapshot_directory=None)\n",
        "\n",
        "# Log total number of iterations\n",
        "decision_tree = DecisionTreeClassifier() \n",
        "decision_tree.fit(X_train, Y_train)  \n",
        "Y_pred = decision_tree.predict(X_test) \n",
        "acc_decision_tree = round(decision_tree.score(X_train, Y_train) * 100, 2)\n",
        "# Log final results\n",
        "run.log(\"Final estimate\", acc_decision_tree)\n",
        "#run.log(\"Final error\",math.pi-pi_estimate)\n",
        "\n",
        "# Write file containing pi value into run history\n",
        "#with open(\"pi_estimate.txt\",\"wb\") as f:\n",
        "    #pickle.dump(str(pi_estimate),f)\n",
        "filename = 'finalized_model.sav'\n",
        "pickle.dump(decision_tree , open(filename, 'wb'))\n",
        "run.upload_file(name = 'outputs/finalized_model.sav', path_or_stream = './finalized_model.sav')\n",
        "\n",
        "# Complete tracking and get link to details\n",
        "run.complete()\n",
        "print(\"Run completed\")"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Run completed\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "precision    recall  f1-score   support\n\n     class 0       0.78      0.91      0.84       274\n     class 1       0.77      0.56      0.65       158\n\n    accuracy                           0.78       432\n   macro avg       0.78      0.73      0.75       432\nweighted avg       0.78      0.78      0.77       432\n\n"
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(Y_test,Y_pred, target_names=['class 0', 'class 1']))"
      ]
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": [
        "run"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "Run(Experiment: titanic-classifier,\nId: aaa80263-cb85-4853-8169-db3e3420b846,\nType: None,\nStatus: Completed)",
            "text/html": "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>titanic-classifier</td><td>aaa80263-cb85-4853-8169-db3e3420b846</td><td></td><td>Completed</td><td><a href=\"https://ml.azure.com/experiments/titanic-classifier/runs/aaa80263-cb85-4853-8169-db3e3420b846?wsid=/subscriptions/d87d4530-ce4e-4d84-b997-7a78d01e2906/resourcegroups/mlops-RG/workspaces/mlops-AML-WS\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.run.Run?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "experiment"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "Experiment(Name: titanic-classifier,\nWorkspace: mlops-AML-WS)",
            "text/html": "<table style=\"width:100%\"><tr><th>Name</th><th>Workspace</th><th>Report Page</th><th>Docs Page</th></tr><tr><td>titanic-classifier</td><td>mlops-AML-WS</td><td><a href=\"https://ml.azure.com/experiments/titanic-classifier?wsid=/subscriptions/d87d4530-ce4e-4d84-b997-7a78d01e2906/resourcegroups/mlops-RG/workspaces/mlops-AML-WS\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.experiment.Experiment?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "Run(Experiment: titanic-classifier,\nId: c0de61c7-44f4-4900-be99-9d488156473f,\nType: None,\nStatus: Completed)",
            "text/html": "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>titanic-classifier</td><td>c0de61c7-44f4-4900-be99-9d488156473f</td><td></td><td>Completed</td><td><a href=\"https://ml.azure.com/experiments/titanic-classifier/runs/c0de61c7-44f4-4900-be99-9d488156473f?wsid=/subscriptions/d87d4530-ce4e-4d84-b997-7a78d01e2906/resourcegroups/mlops-RG/workspaces/mlops-AML-WS\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.run.Run?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "run = list(Experiment(workspace = ws, name = experiment.name).get_runs())[0]\n",
        "run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = run.register_model(model_name = \"titanic_classifier\", model_path = \"outputs/finalized_model.sav\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting score.py\n"
        }
      ],
      "source": [
        "%%writefile score.py\n",
        "import pickle, json\n",
        "from azureml.core.model import Model\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from inference_schema.schema_decorators import input_schema, output_schema\n",
        "from inference_schema.parameter_types.numpy_parameter_type import NumpyParameterType\n",
        "from inference_schema.parameter_types.pandas_parameter_type import PandasParameterType\n",
        "from sklearn.externals import joblib\n",
        "\n",
        "def init():\n",
        "    global titanic_classifier\n",
        "    model_path = Model.get_model_path(model_name = \"titanic_classifier\")\n",
        "    #model_path = \"finalized_model.sav\"\n",
        "    #with open(model_path, \"rb\") as f:\n",
        "    titanic_classifier = joblib.load(model_path)\n",
        "\n",
        "input_sample = pd.DataFrame(data=[{\n",
        "    \"age\": 20,\n",
        "    \"pclass\": 1,\n",
        "    \"unaccompanied\" : 0,\n",
        "    \"sex\" : 0\n",
        "}])\n",
        "\n",
        "output_sample = np.array([0])\n",
        "\n",
        "@input_schema('data', PandasParameterType(input_sample))\n",
        "@output_schema(NumpyParameterType(output_sample))\n",
        "def run(data):\n",
        "    try:\n",
        "        result = titanic_classifier.predict(data)\n",
        "        return result.tolist()\n",
        "    except Exception as e:\n",
        "        result = str(e)\n",
        "        return error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "'myenv.yml'"
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "from azureml.core.conda_dependencies import CondaDependencies \n",
        "\n",
        "cd = CondaDependencies()\n",
        "cd.add_pip_package(\"inference-schema[numpy-support]\")\n",
        "cd.add_conda_package(\"scikit-learn\")\n",
        "cd.add_conda_package(\"pandas\")\n",
        "cd.add_conda_package(\"numpy\")\n",
        "\n",
        "cd.save_to_file(\".\", \"myenv.yml\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "AciWebservice(workspace=Workspace.create(name='mlops-AML-WS', subscription_id='d87d4530-ce4e-4d84-b997-7a78d01e2906', resource_group='mlops-RG'), name=titanic-classifier, image_id=None, compute_type=None, state=ACI, scoring_uri=Transitioning, tags=None, properties={}, created_by={'azureml.git.repository_uri': 'https://github.com/kthejoker/Presentations.git', 'mlflow.source.git.repoURL': 'https://github.com/kthejoker/Presentations.git', 'azureml.git.branch': 'master', 'mlflow.source.git.branch': 'master', 'azureml.git.commit': '0116f681f658ac8daa8bed51009c9489f4664760', 'mlflow.source.git.commit': '0116f681f658ac8daa8bed51009c9489f4664760', 'azureml.git.dirty': 'True'})"
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "from azureml.core.model import InferenceConfig, Model\n",
        "from azureml.core.webservice import AciWebservice\n",
        "from azureml.core import Environment\n",
        "\n",
        "e = Environment.from_conda_specification(\"myenv\", \"./myenv.yml\")\n",
        "\n",
        "inference_config = InferenceConfig(entry_script='score.py', runtime='python', conda_file='myenv.yml')\n",
        "aci_config = AciWebservice.deploy_configuration(cpu_cores=1, memory_gb=1)\n",
        "\n",
        "service = Model.deploy(workspace=ws, name='titanic-classifier', models=[model], inference_config=inference_config, deployment_config=aci_config, deployment_target=None)\n",
        "\n",
        "service.update(description='Binary classifier for Titanic')\n",
        "service.wait_for_deployment(show_output = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [],
      "source": [
        "service.update(models=[model], inference_config = inference_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "[0, 0]"
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "   import json\n",
        "   from azureml.core import Webservice\n",
        "\n",
        "   service = Webservice(workspace=ws, name=\"titanic-classifier\")\n",
        "    \n",
        "   request = json.dumps({\"data\" : [{\"sex\": 0, \"pclass\" : 3, \"age\": 70, \"unaccompanied\": 0}, {\"sex\": 1, \"pclass\" : 1, \"age\": 34, \"unaccompanied\": 1}]})\n",
        "   response = service.run(request)\n",
        "   response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "service.state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1-final",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}